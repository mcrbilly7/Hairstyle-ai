<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>AI On-Demand Hairstyle Try-On (Single file)</title>

<!-- MediaPipe FaceMesh to auto-fit -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

<style>
  :root{--bg:#071023;--panel:linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01));--accent:#7c3aed;--muted:#9aa4b2;--white:#e6eef6}
  *{box-sizing:border-box}
  html,body{height:100%;margin:0;font-family:Inter,system-ui,-apple-system,"Segoe UI",Roboto,Arial;background:linear-gradient(180deg,var(--bg),#04101a);color:var(--white)}
  .container{padding:12px;display:flex;flex-direction:column;gap:12px;height:100vh}
  header{display:flex;justify-content:space-between;align-items:center}
  h1{margin:0;font-size:18px}
  .layout{display:grid;grid-template-columns:360px 1fr;gap:12px;flex:1;min-height:0}
  .panel{background:var(--panel);border-radius:12px;padding:12px;box-shadow:0 6px 20px rgba(0,0,0,0.5);border:1px solid rgba(255,255,255,0.03);overflow:hidden}
  .video-wrap{position:relative;border-radius:12px;overflow:hidden;background:#000;display:flex;align-items:center;justify-content:center;height:100%}
  video#cam{width:100%;height:100%;object-fit:cover;transform:scaleX(-1)}
  canvas#overlayCanvas{position:absolute;left:0;top:0;width:100%;height:100%;pointer-events:none}
  label{font-size:12px;color:var(--muted);display:block;margin-bottom:6px}
  input, select, textarea, button{font-family:inherit}
  input[type=text], select, textarea{width:100%;padding:8px;border-radius:8px;border:1px solid rgba(255,255,255,0.06);background:transparent;color:var(--white)}
  .row{display:flex;gap:8px;align-items:center}
  .controls{display:flex;flex-direction:column;gap:8px}
  .btn{background:var(--accent);border:none;color:white;padding:8px 10px;border-radius:8px;cursor:pointer}
  .btn.ghost{background:transparent;border:1px solid rgba(255,255,255,0.06)}
  .small{font-size:12px;color:var(--muted)}
  .thumbs{display:grid;grid-template-columns:repeat(3,1fr);gap:8px;max-height:40vh;overflow:auto;padding:6px}
  .thumb{background:#071227;border-radius:8px;padding:6px;display:flex;align-items:center;justify-content:center;border:1px solid rgba(255,255,255,0.02);height:90px}
  .thumb img{max-width:100%;max-height:100%;border-radius:6px;object-fit:cover}
  .progress{height:8px;background:rgba(255,255,255,0.04);border-radius:6px;overflow:hidden}
  .progress > i{display:block;height:100%;background:linear-gradient(90deg,#7c3aed,#0ea5a6);width:0%}
  footer{font-size:12px;color:var(--muted);text-align:center;padding:6px}
  @media(max-width:900px){.layout{grid-template-columns:1fr}.thumbs{grid-template-columns:repeat(2,1fr)}}
</style>
</head>
<body>
<div class="container">
  <header>
    <div>
      <h1>AI On-Demand Hairstyle Try-On</h1>
      <div class="small">Generates realistic full-head hairstyles on demand via an AI image API and auto-fits them to your live camera using FaceMesh.</div>
    </div>

    <div style="display:flex;gap:8px;align-items:center">
      <div id="status" class="small">Camera: off</div>
      <button id="startCamera" class="btn">Start Camera</button>
      <button id="snap" class="btn ghost">Snapshot</button>
    </div>
  </header>

  <div class="layout">
    <!-- controls / sidebar -->
    <aside class="panel">
      <div class="controls">
        <label>AI Provider (choose) — for quick test use "replicate" or "stability" or "proxy"</label>
        <select id="provider">
          <option value="replicate">Replicate (client)</option>
          <option value="stability">Stability.ai (DreamStudio client)</option>
          <option value="proxy">Custom Proxy (recommended)</option>
        </select>

        <label>API Key / Proxy URL</label>
        <input id="apiKeyOrUrl" type="text" placeholder="Replicate API token OR Stability API key OR proxy POST URL" />

        <label>Prompt (try: "ultra-realistic full head hairstyle, natural lighting, transparent background")</label>
        <textarea id="prompt" rows="3">ultra-realistic full-head hairstyle, front-facing, photorealistic, transparent background, natural lighting, high detail</textarea>

        <div class="row">
          <select id="gender">
            <option value="female">Female</option>
            <option value="male">Male</option>
          </select>
          <select id="style">
            <option value="all">Any style</option>
            <option value="short">Short</option>
            <option value="long">Long</option>
            <option value="curly">Curly</option>
            <option value="ponytail">Ponytail</option>
            <option value="fade">Fade</option>
            <option value="braid">Braid</option>
          </select>
          <select id="quality">
            <option value="512">512px</option>
            <option value="768" selected>768px</option>
            <option value="1024">1024px</option>
          </select>
        </div>

        <div class="row">
          <button id="generateBtn" class="btn">Generate Hairstyle</button>
          <button id="applyLast" class="btn ghost">Apply Last</button>
        </div>

        <div class="small">Security note: entering an API key into the page exposes it to this browser session. For production, use provider="proxy" and run a small server that holds the API key server-side.</div>

        <div style="margin-top:8px">
          <div class="progress"><i id="genProgress"></i></div>
          <div id="log" class="small" style="margin-top:6px">Idle</div>
        </div>

        <hr/>
        <div class="small">Generated hairstyles (tap to apply):</div>
        <div id="thumbs" class="thumbs"></div>
      </div>
    </aside>

    <!-- video & overlay -->
    <main class="panel">
      <div class="video-wrap" id="videoPanel" style="height:100%">
        <video id="cam" autoplay playsinline muted></video>
        <canvas id="overlayCanvas"></canvas>
      </div>
    </main>
  </div>

  <footer class="panel small">Use this for testing. For safe production use, run a proxy server (sample code included in comments).</footer>
</div>

<script>
/* =============================
  AI On-Demand Hairstyle Try-On
  - Uses MediaPipe FaceMesh (CDN) for landmarks (auto-fit)
  - Calls an AI image-generation API on demand (Replicate, Stability, or your proxy)
  - Overlays the returned PNG (expected transparent bg) onto camera, auto-fitted via affine mapping
  - IMPORTANT: keep API keys secret in production (use proxy)
=============================*/

const cam = document.getElementById('cam');
const startCameraBtn = document.getElementById('startCamera');
const statusEl = document.getElementById('status');
const overlayCanvas = document.getElementById('overlayCanvas');
const overlayCtx = overlayCanvas.getContext('2d');
const generateBtn = document.getElementById('generateBtn');
const providerSel = document.getElementById('provider');
const apiKeyOrUrlInput = document.getElementById('apiKeyOrUrl');
const promptInput = document.getElementById('prompt');
const genderSel = document.getElementById('gender');
const styleSel = document.getElementById('style');
const qualitySel = document.getElementById('quality');
const progressEl = document.getElementById('genProgress');
const logEl = document.getElementById('log');
const thumbsEl = document.getElementById('thumbs');
const applyLastBtn = document.getElementById('applyLast');
const snapBtn = document.getElementById('snap');

let stream = null, faceMesh = null, cameraFeed = null;
let lastGenerated = null; // {url, anchors}
let generatedList = []; // recent results
let selectedOverlay = null;
let overlayState = { scale: 1, rotate: 0, yOffset: 0, opacity: 1 };
let overlayPos = { xPercent: 50, yPercent: 28 };
let isDragging = false;

/* ---------- MediaPipe FaceMesh setup ---------- */
async function startFaceMeshCamera(){
  try {
    stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:'user',width:{ideal:1280},height:{ideal:720}}, audio:false});
    cam.srcObject = stream;
    statusEl.textContent = 'Camera: on';
    startCameraBtn.textContent = 'Stop Camera';

    faceMesh = new FaceMesh({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}` });
    faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.55, minTrackingConfidence: 0.4 });
    faceMesh.onResults(onFaceResults);

    cameraFeed = new Camera(cam, {
      onFrame: async () => { await faceMesh.send({ image: cam }); },
      width: 1280, height: 720
    });
    cameraFeed.start();

    attachResizeObserver();
    requestAnimationFrame(drawOverlayLoop);
  } catch(e){
    console.error(e);
    alert('Camera error — check permissions and HTTPS (page must be served over HTTPS for camera on some browsers).');
  }
}
function stopFaceMeshCamera(){
  if(cameraFeed && cameraFeed.stop) cameraFeed.stop();
  if(stream){ stream.getTracks().forEach(t=>t.stop()); stream = null; cam.srcObject = null; }
  statusEl.textContent = 'Camera: off';
  startCameraBtn.textContent = 'Start Camera';
  faceMesh = null;
}
startCameraBtn.addEventListener('click', ()=> { if(stream) stopFaceMeshCamera(); else startFaceMeshCamera(); });

let lastLandmarks = null;
function onFaceResults(results){
  lastLandmarks = (results.multiFaceLandmarks && results.multiFaceLandmarks[0]) ? results.multiFaceLandmarks[0] : null;
}

/* ---------- Drawing & affine placement ---------- */
function ensureCanvasSize(){
  const rect = document.getElementById('videoPanel').getBoundingClientRect();
  overlayCanvas.width = Math.max(1, Math.floor(rect.width));
  overlayCanvas.height = Math.max(1, Math.floor(rect.height));
  overlayCanvas.style.width = rect.width + 'px';
  overlayCanvas.style.height = rect.height + 'px';
}

function computeAffineFromPoints(srcPts, dstPts){
  // same solver as earlier: returns {a,b,c,d,e,f}
  const A = []; const b = [];
  for(let i=0;i<3;i++){
    const sx=srcPts[i].x, sy=srcPts[i].y, dx=dstPts[i].x, dy=dstPts[i].y;
    A.push([sx,0,sy,0,1,0]); b.push(dx);
    A.push([0,sx,0,sy,0,1]); b.push(dy);
  }
  const n=6; const M = A.map((r,i)=> r.concat([b[i]]));
  for(let i=0;i<n;i++){
    let maxR=i; for(let r=i+1;r<n;r++) if(Math.abs(M[r][i])>Math.abs(M[maxR][i])) maxR=r;
    if(Math.abs(M[maxR][i]) < 1e-12) continue;
    [M[i],M[maxR]]=[M[maxR],M[i]];
    const div=M[i][i];
    for(let c=i;c<=n;c++) M[i][c]/=div;
    for(let r=0;r<n;r++) if(r!==i){
      const f=M[r][i];
      for(let c=i;c<=n;c++) M[r][c]-=f*M[i][c];
    }
  }
  const sol = M.map(r=> r[n] );
  return { a:sol[0], b:sol[1], c:sol[2], d:sol[3], e:sol[4], f:sol[5] };
}

function drawAffineImage(img, srcAnchors, dstAnchors, alpha=1){
  const T = computeAffineFromPoints(srcAnchors, dstAnchors);
  overlayCtx.save();
  overlayCtx.globalAlpha = alpha;
  overlayCtx.setTransform(T.a, T.b, T.c, T.d, T.e, T.f);
  overlayCtx.drawImage(img, 0, 0);
  overlayCtx.restore();
}

function fallbackAnchors(canvasW, canvasH){
  return [{x:canvasW*0.22,y:canvasH*0.36},{x:canvasW*0.78,y:canvasH*0.36},{x:canvasW*0.5,y:canvasH*0.12}];
}

function drawOverlayLoop(){
  ensureCanvasSize();
  overlayCtx.clearRect(0,0,overlayCanvas.width,overlayCanvas.height);
  if(selectedOverlay && selectedOverlay.url){
    const img = new Image();
    img.onload = ()=>{
      // src anchors from overlay (in overlay image pixel coords) or default
      const srcAnch = selectedOverlay.anchors || [{x:img.width*0.2,y:img.height*0.4},{x:img.width*0.8,y:img.height*0.4},{x:img.width*0.5,y:img.height*0.12}];
      // dst anchors from lastLandmarks if available
      let dstAnch = null;
      if(lastLandmarks && lastLandmarks.length){
        const L = lastLandmarks[234] || lastLandmarks[130] || lastLandmarks[33];
        const R = lastLandmarks[454] || lastLandmarks[359] || lastLandmarks[263];
        const T = lastLandmarks[10] || lastLandmarks[9] || lastLandmarks[151];
        if(L && R && T){
          const w = overlayCanvas.width, h = overlayCanvas.height;
          const toCanvas = (lm) => ({ x: (1 - lm.x) * w, y: lm.y * h + overlayState.yOffset });
          dstAnch = [ toCanvas(L), toCanvas(R), toCanvas(T) ];
        }
      }
      if(!dstAnch) dstAnch = fallbackAnchors(overlayCanvas.width, overlayCanvas.height);
      // apply scale around centroid then rotation then affine
      const cx = (dstAnch[0].x + dstAnch[1].x + dstAnch[2].x)/3;
      const cy = (dstAnch[0].y + dstAnch[1].y + dstAnch[2].y)/3;
      let scaled = dstAnch.map(p => ({ x: cx + (p.x - cx) * overlayState.scale, y: cy + (p.y - cy) * overlayState.scale }));
      if(Math.abs(overlayState.rotate) > 0.0001){
        const ang = overlayState.rotate * Math.PI/180;
        const s = Math.sin(ang), c = Math.cos(ang);
        scaled = scaled.map(p => { const dx = p.x - cx, dy = p.y - cy; return { x: cx + dx * c - dy * s, y: cy + dx * s + dy * c }; });
      }
      drawAffineImage(img, srcAnch, scaled, overlayState.opacity);
    };
    img.crossOrigin = 'anonymous';
    img.src = selectedOverlay.url;
  }
  requestAnimationFrame(drawOverlayLoop);
}

/* ---------- Thumbnail management ---------- */
function addGeneratedThumb(obj){
  generatedList.unshift(obj);
  if(generatedList.length > 24) generatedList.pop(); // limit UI to last 24
  renderThumbs();
}
function renderThumbs(){
  thumbsEl.innerHTML = '';
  for(const item of generatedList){
    const d = document.createElement('div'); d.className='thumb';
    const img = document.createElement('img'); img.src = item.url; d.appendChild(img);
    d.addEventListener('click', ()=> { selectedOverlay = item; log('Applied ' + item.id); });
    thumbsEl.appendChild(d);
  }
}

/* ---------- Generation API glue ----------
  We support 3 modes:
  - provider="replicate": send to Replicate API directly (client-side). Example usage below.
  - provider="stability": call Stability.ai REST (DreamStudio) directly.
  - provider="proxy": POST to a user-provided proxy URL which must accept JSON {prompt,width,mask?} and return {dataUrl}
  NOTE: For Replicate & Stability you must supply a valid API token in the "API Key / Proxy URL" field.
-------------------------------------------------*/

function setProgress(pct, text=''){
  progressEl.style.width = pct + '%';
  if(text) log(text);
}
function log(msg){ logEl.textContent = msg; }

async function generateImageViaReplicate(prompt, width){
  // NOTE: This is a simplified example. Replicate's API requires a model version UUID.
  // You must replace MODEL_VERSION with the specific model version id you want to run.
  // Example: "stability-ai/stable-diffusion-xl" requires a version id; see Replicate docs.
  const token = (document.getElementById('apiKeyOrUrl').value || '').trim();
  if(!token) throw new Error('Replicate API token required');
  // ---- REPLACE this model version with the one you intend to use (look up on replicate.com) ----
  const MODEL_VERSION = 'stability-ai/stable-diffusion-xl'; // placeholder (may not work); better: use a proxy
  // For many replicate models you do:
  // POST https://api.replicate.com/v1/predictions
  // body: { "version": "<version-id>", "input": { "prompt": "...", "image_dimensions": "1024x1024", ... } }
  // Here we attempt a generic request — you may need to adjust per model.
  const body = {
    version: MODEL_VERSION,
    input: {
      prompt,
      width: width,
      height: width, // square outputs recommended for overlays
      // if model supports transparent background: set that in input (model-dependent)
      // e.g., "transparent_background": true
    }
  };
  const resp = await fetch('https://api.replicate.com/v1/predictions', {
    method: 'POST',
    headers: {
      'Authorization': `Token ${token}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(body)
  });
  if(!resp.ok) {
    const txt = await resp.text();
    throw new Error('Replicate request failed: ' + resp.status + ' ' + txt);
  }
  const data = await resp.json();
  // Poll the prediction URL until complete (Replicate returns a URL in data.urls.get)
  const getUrl = data.urls && data.urls.get;
  if(!getUrl) throw new Error('Replicate response missing polling url.');
  // poll
  for(let attempt=0; attempt<120; attempt++){
    const p = await fetch(getUrl, { headers: { 'Authorization': `Token ${token}` }});
    const pj = await p.json();
    if(pj.status === 'succeeded' && pj.output && pj.output.length){
      // output may be an array of URLs
      // We need a PNG with transparent background or at least a figure to alpha out — depends on model
      const imageUrl = pj.output[0];
      // fetch image as blob and convert to data URL
      const imageResp = await fetch(imageUrl);
      const blob = await imageResp.blob();
      const dataUrl = await blobToDataURL(blob);
      return dataUrl;
    } else if(pj.status === 'failed'){
      throw new Error('Generation failed: ' + JSON.stringify(pj));
    }
    setProgress(Math.min(98, (attempt/120)*100), `Waiting for replicate (${attempt})`);
    await new Promise(r=>setTimeout(r, 1500));
  }
  throw new Error('Replicate generation timed out');
}

async function generateImageViaStability(prompt, width){
  // This uses Stability.ai's REST /v1/generation/<engine>/text-to-image endpoint (DreamStudio).
  // You must provide your Stability API key in the field.
  const key = (document.getElementById('apiKeyOrUrl').value || '').trim();
  if(!key) throw new Error('Stability API key required');
  // Using stable-diffusion-v1 or stable-diffusion-xl or "stable-inpainting" engine names may vary.
  // This is an example for "stable-diffusion-xl" style; adjust accordingly.
  const engine = 'stable-diffusion-xl-beta-v0-9'; // may change over time
  const url = `https://api.stability.ai/v1/generation/${engine}/text-to-image`;
  const body = {
    text_prompts: [{ text: prompt, weight: 1 }],
    cfg_scale: 7,
    height: width,
    width: width,
    samples: 1,
    // Some Stability endpoints support "background" "transparent" flags — consult docs for your engine
  };
  const resp = await fetch(url, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${key}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(body)
  });
  if(!resp.ok){
    const t = await resp.text();
    throw new Error('Stability request failed: ' + resp.status + ' ' + t);
  }
  const result = await resp.json();
  // result.artifacts[0].base64 or b64_json depending on engine
  // Many stability endpoints return base64-encoded images
  const artifact = result.artifacts && result.artifacts[0];
  if(!artifact) throw new Error('No image returned by Stability');
  // If b64_png present:
  if(artifact.base64){
    return 'data:image/png;base64,' + artifact.base64;
  } else if(artifact.b64_json){
    return 'data:image/png;base64,' + artifact.b64_json;
  } else {
    throw new Error('Stability returned unexpected artifact format');
  }
}

async function generateViaProxy(prompt, width){
  // Proxy endpoint is a user-provided POST URL that accepts JSON:
  // { prompt: "...", width: 768, gender: "female", style: "curly" }
  // and returns JSON { dataUrl: "data:image/png;base64,..." }
  const url = (document.getElementById('apiKeyOrUrl').value || '').trim();
  if(!url) throw new Error('Proxy URL required (enter the POST endpoint in the field).');
  const resp = await fetch(url, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ prompt, width, gender: genderSel.value, style: styleSel.value })
  });
  if(!resp.ok) {
    const text = await resp.text();
    throw new Error('Proxy returned error: ' + resp.status + ' ' + text);
  }
  const j = await resp.json();
  if(!j.dataUrl) throw new Error('Proxy response missing dataUrl');
  return j.dataUrl;
}

async function blobToDataURL(blob){
  return new Promise((res,rej) => {
    const r = new FileReader();
    r.onload = ()=>res(r.result);
    r.onerror = rej;
    r.readAsDataURL(blob);
  });
}

/* ---------- main generate handler ---------- */
generateBtn.addEventListener('click', async ()=>{
  try{
    setProgress(4);
    logEl.textContent = 'Preparing generation...';
    const provider = providerSel.value;
    const promptBase = (promptInput.value || '').trim();
    const style = styleSel.value;
    const gender = genderSel.value;
    const width = parseInt(qualitySel.value, 10);

    // craft final prompt (you can tinker with this)
    const prompt = `${promptBase}, ${gender} ${style} hairstyle, ultra-realistic, full-head coverage, transparent background, high detail, photorealistic, front-facing`;

    setProgress(10, 'Sending request to AI provider...');
    let dataUrl = null;
    if(provider === 'replicate'){
      dataUrl = await generateImageViaReplicate(prompt, width);
    } else if(provider === 'stability'){
      dataUrl = await generateImageViaStability(prompt, width);
    } else {
      dataUrl = await generateViaProxy(prompt, width);
    }

    setProgress(85, 'Received image — processing...');
    // create default anchors (full-head generator returns anchors if proxy/model supports it — we default)
    const anchors = null; // if provider returns anchors, use them. For now we assume typical overlay coords
    const id = 'ai-' + Date.now();
    const obj = { id, url: dataUrl, anchors, gender, prompt };
    lastGenerated = obj;
    addGeneratedThumb(obj);
    selectedOverlay = obj;
    setProgress(100, 'Ready — applied');
    setTimeout(()=> setProgress(0), 700);
    log('Generation complete — added to gallery.');
  } catch(err){
    console.error(err);
    alert('Generation error: ' + (err.message || err));
    setProgress(0);
    log('Error: ' + (err.message||err));
  }
});

/* apply last quick button */
applyLastBtn.addEventListener('click', ()=> {
  if(lastGenerated){ selectedOverlay = lastGenerated; log('Applied last generated'); }
  else log('No last generated image yet');
});

/* ---------- thumbnails & gallery ---------- */
function addGeneratedThumb(obj){
  generatedList.unshift(obj);
  if(generatedList.length > 36) generatedList.pop();
  renderThumbs();
}
function renderThumbs(){
  thumbsEl.innerHTML = '';
  for(const it of generatedList){
    const d = document.createElement('div'); d.className='thumb';
    const img = document.createElement('img'); img.src = it.url; d.appendChild(img);
    d.addEventListener('click', ()=> { selectedOverlay = it; log('Applied ' + it.id); });
    thumbsEl.appendChild(d);
  }
}

/* ---------- snapshot ---------- */
snapBtn.addEventListener('click', ()=> {
  if(!stream){ alert('Start camera first'); return; }
  ensureCanvasSize();
  const w = overlayCanvas.width, h = overlayCanvas.height;
  const tmp = document.createElement('canvas'); tmp.width = w; tmp.height = h;
  const ctx = tmp.getContext('2d');
  ctx.save(); ctx.scale(-1,1); ctx.drawImage(cam, -w, 0, w, h); ctx.restore();
  ctx.drawImage(overlayCanvas, 0, 0);
  tmp.toBlob(blob => {
    const a = document.createElement('a'); a.href = URL.createObjectURL(blob); a.download = `hairstyle-${Date.now()}.png`; document.body.appendChild(a); a.click(); a.remove();
  }, 'image/png');
});

/* ---------- resize observer ---------- */
function attachResizeObserver(){
  const ro = new ResizeObserver(()=> ensureCanvasSize());
  ro.observe(document.getElementById('videoPanel'));
}

/* ---------- utility UI ---------- */
function setProgress(pct, text=''){
  document.getElementById('genProgress').style.width = pct + '%';
  if(text) log(text);
}
function log(msg){ logEl.textContent = msg; }

/* ---------- lightweight helpers ---------- */
async function init(){
  // nothing heavy on load; user clicks Generate when ready
  log('Ready — choose provider and click Generate');
}
init();

/* ---------- Proxy server example (Node.js + Express) ----------
 You should run a small server that accepts client POSTs and calls the AI provider with your secret key.
 Example (very small, not production hardened):

 // server.js
 const express = require('express');
 const fetch = require('node-fetch');
 const app = express();
 app.use(express.json({limit:'10mb'}));

 // Example proxy for Stability (replace with your provider)
 app.post('/generate', async (req, res) => {
   const { prompt, width } = req.body;
   const STABILITY_KEY = process.env.STABILITY_KEY;
   const engine = 'stable-diffusion-xl-beta-v0-9';
   const response = await fetch(`https://api.stability.ai/v1/generation/${engine}/text-to-image`, {
     method: 'POST',
     headers: { 'Authorization': `Bearer ${STABILITY_KEY}`, 'Content-Type': 'application/json' },
     body: JSON.stringify({
       text_prompts:[{text:prompt}],
       width, height: width, samples:1
     })
   });
   const j = await response.json();
   // extract base64 from j.artifacts[0].base64 (engine-dependent)
   const b64 = j.artifacts[0].base64;
   res.json({ dataUrl: 'data:image/png;base64,' + b64 });
 });

 app.listen(3000, ()=> console.log('proxy running on :3000'));

 NOTE: use HTTPS in production, protect endpoints, validate input size, and do rate-limiting.
----------------------------------------------------------------- */

</script>
</body>
  </html>
        <div class="search">
          <input id="quickSearch" placeholder="Search tags or #index (e.g., curly, #23)" style="flex:1;padding:8px;border-radius:8px;border:1px solid rgba(255,255,255,0.04);background:transparent;color:var(--white)">
          <button id="clearSearch" class="chip">Clear</button>
        </div>

        <div class="small">Auto-fit uses MediaPipe FaceMesh for best positioning. Use drag/scale/rotate for fine-tune.</div>

        <div class="sliders">
          <div class="slider-row"><label style="width:80px">Scale</label><input id="scale" type="range" min="0.25" max="4" step="0.01" value="1"></div>
          <div class="slider-row"><label style="width:80px">Rotate</label><input id="rotate" type="range" min="-90" max="90" step="0.1" value="0"></div>
          <div class="slider-row"><label style="width:80px">Y offset</label><input id="voffset" type="range" min="-400" max="400" step="1" value="0"></div>
          <div class="slider-row"><label style="width:80px">Opacity</label><input id="opacity" type="range" min="0" max="1" step="0.01" value="1"></div>
        </div>

        <div style="display:flex;gap:8px;flex-wrap:wrap">
          <button id="fitBtn" class="btn ghost">Auto-fit</button>
          <button id="resetBtn" class="btn ghost">Reset</button>
          <button id="randomBtn" class="chip">Randomize</button>
          <button id="orderReset" class="chip">Reset Order</button>
        </div>

        <div style="display:flex;justify-content:space-between;align-items:center">
          <div class="small" id="thumbCount">Generating 200 styles…</div>
          <div class="small hint">Tap thumbnail to apply</div>
        </div>

        <div class="progress" aria-hidden="true" style="margin-top:8px"><i id="genProgress"></i></div>

        <div id="thumbs" class="thumbs" aria-live="polite" role="list"></div>

        <hr style="border:none;border-top:1px solid rgba(255,255,255,0.03)">

        <div class="small">Upload your own transparent PNG overlays (stays on your device):</div>
        <div style="display:flex;gap:8px;align-items:center">
          <label for="fileUpload" class="dropzone">Click/Drop PNGs</label>
          <input id="fileUpload" type="file" accept="image/png,image/webp" multiple>
          <button id="clearUploads" class="chip">Clear Uploads</button>
        </div>

        <div class="small">Note: Generating 200 ultra-realistic overlays may take a few seconds — progress shown above.</div>
      </div>
    </aside>

    <main class="panel">
      <div class="video-wrap" id="videoPanel" style="height:100%">
        <video id="cam" autoplay playsinline muted></video>
        <canvas id="overlayCanvas"></canvas>
      </div>
    </main>
  </div>

  <footer class="panel footer-note">
    Everything runs locally in the browser. For best performance use Chrome or Edge on a modern device.
  </footer>
</div>

<script>
/* ========================================================
   Ultra-Realistic 200 Hair Try-On (Single File)
   - Generates 200 high-quality transparent PNG hair overlays
     (100 boys + 100 girls) in-browser at load time.
   - Uses MediaPipe FaceMesh (CDN) for auto-fit positioning/rotation/scale.
   - Manual drag/scale/rotate/opacity + snapshot download.
   - All overlays are generated at runtime and used as data-URIs.
   ======================================================== */

const cam = document.getElementById('cam');
const startBtn = document.getElementById('startBtn');
const snapBtn = document.getElementById('snapBtn');
const statusEl = document.getElementById('status');
const thumbsEl = document.getElementById('thumbs');
const boysBtn = document.getElementById('boysBtn');
const girlsBtn = document.getElementById('girlsBtn');
const thumbCount = document.getElementById('thumbCount');
const genProgressEl = document.getElementById('genProgress');
const fitBtn = document.getElementById('fitBtn');
const resetBtn = document.getElementById('resetBtn');
const randomBtn = document.getElementById('randomBtn');
const orderReset = document.getElementById('orderReset');
const scaleSlider = document.getElementById('scale');
const rotateSlider = document.getElementById('rotate');
const voffsetSlider = document.getElementById('voffset');
const opacitySlider = document.getElementById('opacity');
const overlayCanvas = document.getElementById('overlayCanvas');
const overlayCtx = overlayCanvas.getContext('2d');
const stylePreset = document.getElementById('stylePreset');
const quickSearch = document.getElementById('quickSearch');
const clearSearch = document.getElementById('clearSearch');
const fileUpload = document.getElementById('fileUpload');
const clearUploads = document.getElementById('clearUploads');

let stream = null, faceMesh = null, cameraFeed = null;
let currentGender = 'boys';
let uploadedOverlays = [];        // user uploaded PNGs
let generatedOverlays = [];       // programmatically generated PNG overlays
let selectedItem = null;          // currently applied overlay object {id,url,tags,gender,idx}
let overlayState = { scale:1, rotate:0, yOffset:0, opacity:1 };
let overlayPos = { xPercent:50, yPercent:32 };
let isDragging = false;
let boysList = [], girlsList = [];
let displayList = [];

/* -------------------------
  Utilities
  ------------------------- */
function uid(prefix='id'){ return prefix + '-' + Math.random().toString(36).slice(2,9); }
function clamp(v,a,b){ return Math.max(a,Math.min(b,v)); }
function hexToRgb(hex){ const num=parseInt(hex.slice(1),16); return {r:(num>>16)&255,g:(num>>8)&255,b:num&255}; }

/* color palette for hair tones */
const HAIR_PALETTE = ["#1b120f","#24120f","#2f1b14","#56331f","#6b3a22","#7a4a2b","#8b5b2f","#9a6a3a","#b7884f","#c79b63","#d6b78a","#a16207","#4c1d95","#0b3b3b"];

/* -------------------------
  Advanced photorealistic-like hair generator (canvas)
  - Generates transparent PNG hair overlays with:
    - base shape (blob), radial gradients, layered shadows
    - many hair strands with curved strokes
    - subtle noise and highlights
    - slight accessory options (flower/band) on some images
  - returns dataURL PNG
  ------------------------- */
function generateHairPNG({seed=0, gender='boys', family=0, idx=0}) {
  // deterministic-ish randomness via seeded RNG
  let s = seed || (idx+1);
  function rnd() { s = (s * 1664525 + 1013904223) >>> 0; return (s % 1000)/1000; }

  const w = 900, h = 700;
  const c = document.createElement('canvas'); c.width=w; c.height=h;
  const ctx = c.getContext('2d');
  ctx.clearRect(0,0,w,h);

  // choose base color
  const baseColor = HAIR_PALETTE[(idx + (gender==='girls'?3:0)) % HAIR_PALETTE.length];
  const base = hexToRgb(baseColor);

  // draw soft volume (randomized blob)
  ctx.save();
  const cx = w/2 + (rnd()-0.5)*80;
  const cy = h*0.28 + (rnd()-0.5)*40;
  const rx = w*0.42 + (rnd()-0.5)*60;
  const ry = h*0.28 + (rnd()-0.5)*40;
  const g = ctx.createRadialGradient(cx, cy, rx*0.15, cx - rx*0.05, cy - ry*0.02, rx*1.05);
  const lighten = (v, amt)=>({ r: clamp(v.r+amt,0,255), g: clamp(v.g+amt,0,255), b: clamp(v.b+amt,0,255) });
  const hl = lighten(base, 36), sh = lighten(base, -36);
  g.addColorStop(0, `rgb(${hl.r},${hl.g},${hl.b})`);
  g.addColorStop(0.6, `rgb(${base.r},${base.g},${base.b})`);
  g.addColorStop(1, `rgb(${sh.r},${sh.g},${sh.b})`);
  ctx.fillStyle = g;

  // blob path (irregular)
  ctx.beginPath();
  const steps = 48;
  for (let i=0;i<=steps;i++){
    const a = (i/steps) * Math.PI * 2;
    const rxf = rx * (1 + Math.sin(a*2.1 + rnd()*2)*0.06 + (rnd()-0.5)*0.04);
    const ryf = ry * (1 + Math.cos(a*1.7 + rnd()*3)*0.06 + (rnd()-0.5)*0.03);
    const x = cx + Math.cos(a) * rxf;
    const y = cy + Math.sin(a) * ryf;
    if (i===0) ctx.moveTo(x,y); else ctx.lineTo(x,y);
  }
  ctx.closePath();
  ctx.fill();
  ctx.restore();

  // mid shadow layer for depth
  ctx.save();
  ctx.globalAlpha = 0.12;
  ctx.fillStyle = `rgb(${sh.r},${sh.g},${sh.b})`;
  ctx.beginPath();
  ctx.ellipse(cx+6, cy+10, rx*0.98, ry*0.98, 0, 0, Math.PI*2);
  ctx.fill();
  ctx.restore();

  // draw many hair strands with varying widths and alpha
  ctx.save();
  ctx.lineCap = 'round';
  ctx.lineJoin = 'round';
  const strandBase = 120 + Math.floor(rnd()*240);
  for (let sI=0; sI<strandBase; sI++){
    const px = cx - rx*0.85 + rnd()*rx*1.7;
    const py = cy - ry*0.7 + rnd()*ry*1.2;
    const ex = px + (rnd()*220 - 110) + (idx%7)*3;
    const ey = py + (rnd()*320 + 80);
    const cpX = px + (rnd()*140 - 70);
    const cpY = py + (rnd()*120 - 60);
    const width = 0.4 + rnd()*2.6;
    const alpha = 0.03 + rnd()*0.18;
    ctx.beginPath();
    ctx.moveTo(px,py);
    ctx.quadraticCurveTo(cpX, cpY, ex, ey);
    // color slight variation for strand
    const vr = clamp(base.r + Math.floor((rnd()-0.5)*40), 0, 255);
    const vg = clamp(base.g + Math.floor((rnd()-0.5)*40), 0, 255);
    const vb = clamp(base.b + Math.floor((rnd()-0.5)*40), 0, 255);
    ctx.strokeStyle = `rgba(${vr},${vg},${vb},${alpha})`;
    ctx.lineWidth = width;
    ctx.stroke();
  }
  ctx.restore();

  // highlights: draw a few brighter strokes
  ctx.save();
  ctx.globalCompositeOperation = 'lighter';
  for (let hI=0; hI<8; hI++){
    const sx = cx - rx*0.65 + rnd()*rx*1.3;
    const sy = cy - ry*0.4 + rnd()*ry*0.6;
    const ex = sx + (rnd()*220 - 110);
    const ey = sy + (rnd()*260 + 40);
    const cpX = sx + (rnd()*100 - 50);
    const cpY = sy + (rnd()*90 - 40);
    ctx.beginPath();
    ctx.moveTo(sx,sy);
    ctx.quadraticCurveTo(cpX, cpY, ex, ey);
    ctx.strokeStyle = `rgba(${hl.r},${hl.g},${hl.b},${0.12 + rnd()*0.18})`;
    ctx.lineWidth = 1 + rnd()*3;
    ctx.stroke();
  }
  ctx.restore();

  // subtle grain/noise to simulate texture
  addNoise(ctx, w, h, 0.03 + rnd()*0.06);

  // occasional accessory for some generated items
  if ((idx % 13) === 0) {
    ctx.save();
    ctx.fillStyle = 'rgba(255,210,110,0.95)';
    ctx.beginPath(); ctx.arc(w*0.78, h*0.18, 14 + Math.floor(rnd()*10), 0, Math.PI*2); ctx.fill();
    ctx.restore();
  }

  // final trim: make edges soft
  ctx.save();
  ctx.globalCompositeOperation = 'destination-in';
  const mask = ctx.createLinearGradient(0,0,0,h);
  mask.addColorStop(0, 'rgba(255,255,255,1)');
  mask.addColorStop(1, 'rgba(255,255,255,0.98)');
  ctx.fillStyle = mask;
  roundClip(ctx, cx, cy, rx*1.04, ry*1.04, 48);
  ctx.restore();

  // export dataURL
  return c.toDataURL('image/png');
}

// helper: add noise via imageData
function addNoise(ctx, w, h, opacity=0.05){
  const id = ctx.createImageData(w, h);
  for (let i=0;i<id.data.length;i+=4){
    const v = (Math.random()*255)|0;
    id.data[i] = id.data[i+1] = id.data[i+2] = v;
    id.data[i+3] = (opacity*255)|0;
  }
  const tmp = document.createElement('canvas'); tmp.width=w; tmp.height=h;
  const tctx = tmp.getContext('2d'); tctx.putImageData(id,0,0);
  ctx.globalCompositeOperation = 'overlay';
  ctx.drawImage(tmp,0,0);
  ctx.globalCompositeOperation = 'source-over';
}

// helper: draw round clipping path
function roundClip(ctx, cx, cy, rx, ry, steps=48){
  ctx.beginPath();
  for (let i=0;i<=steps;i++){
    const a = (i/steps) * Math.PI*2;
    const x = cx + Math.cos(a)*rx;
    const y = cy + Math.sin(a)*ry;
    if (i===0) ctx.moveTo(x,y); else ctx.lineTo(x,y);
  }
  ctx.closePath();
  ctx.fill();
}

/* -------------------------
  Generate 200 overlays (100 per gender)
  - updates progress bar
  - stores results in generatedOverlays array
  ------------------------- */
async function generateAllOverlays(total=200){
  generatedOverlays = [];
  genProgressEl.style.width = '0%';
  const progressBar = genProgressEl;
  for (let i=0;i<total;i++){
    // alternate gender halves: first 100 boys, next 100 girls
    const gender = (i < total/2) ? 'boys' : 'girls';
    const idx = (gender==='boys') ? (i+1) : (i - total/2 + 1);
    // family seed to vary shapes
    const family = i % 8;
    // small delay periodically to keep UI responsive
    if (i % 20 === 0) await new Promise(r => setTimeout(r, 8));
    const png = generateHairPNG({seed:i+7, gender, family, idx:i});
    const id = `${gender}-${idx}`;
    generatedOverlays.push({ id, url: png, tags: ['generated','png'], gender, idx });
    // update progress bar and label
    const pct = Math.round(((i+1)/total)*100);
    progressBar.style.width = pct + '%';
    thumbCount.textContent = `Generated ${i+1}/${total} styles (${gender}) — finalizing...`;
  }
  thumbCount.textContent = `Ready — ${generatedOverlays.length} generated styles`;
  genProgressEl.style.width = '100%';
  // after generation, assemble library metadata
  buildLibraries();
}

/* -------------------------
  Build static SVG libraries (100 per gender) for variety + combine with generated PNGs
  ------------------------- */
function palette(i){ return HAIR_PALETTE[i % HAIR_PALETTE.length]; }
function makeSimpleSVG({id, idx, gender, family, tags=[]}){
  // compact SVG generator for supplementary vector options
  const baseW=700, baseH=540;
  const mainColor = palette(idx + (gender==='girls'?3:0));
  const grad = `linear-gradient-${id}`;
  const svg = `
  <svg xmlns="http://www.w3.org/2000/svg" width="${baseW}" height="${baseH}" viewBox="0 0 ${baseW} ${baseH}">
    <defs>
      <linearGradient id="${grad}" x1="0" x2="1" y1="0" y2="1">
        <stop offset="0%" stop-color="${mainColor}" stop-opacity="0.95"/>
        <stop offset="100%" stop-color="#111111" stop-opacity="0.9"/>
      </linearGradient>
    </defs>
    <g fill="url(#${grad})">
      <path d="M100 210 C170 110 530 110 600 210 C560 190 460 160 350 180 C240 200 160 210 100 210 Z"/>
    </g>
  </svg>`;
  return 'data:image/svg+xml;charset=utf-8,' + encodeURIComponent(svg);
}

function buildLibraries(){
  boysList = []; girlsList = [];
  for (let i=0;i<100;i++){
    boysList.push({id:`boys-${i+1}`, idx:i+1, url: makeSimpleSVG({id:`boys-${i+1}`, idx:i, gender:'boys', family:i%8}), tags: ['svg','boys'], gender:'boys'});
    girlsList.push({id:`girls-${i+1}`, idx:i+1, url: makeSimpleSVG({id:`girls-${i+1}`, idx:i, gender:'girls', family:i%8}), tags: ['svg','girls'], gender:'girls'});
  }
  // display list initially boys + generated PNGs
  displayList = boysList.concat(generatedOverlays);
  renderThumbnails();
}

/* -------------------------
  Thumbnail rendering
  ------------------------- */
function renderThumbnails(){
  thumbsEl.innerHTML = '';
  // filtered by currentGender selection
  let baseList = (currentGender === 'boys') ? boysList : girlsList;
  // always include generated overlays (both genders) and user uploads
  const combined = baseList.concat(generatedOverlays.filter(g=>g.gender===currentGender || true)).concat(uploadedOverlays);
  // show up to all (performance: thumbnails are small)
  combined.forEach(item=>{
    const div = document.createElement('div'); div.className='thumb'; div.tabIndex=0;
    div.title = item.id + (item.tags ? ' ' + item.tags.join(',') : '');
    const img = document.createElement('img'); img.src = item.url; img.alt = item.id;
    div.appendChild(img);
    div.addEventListener('click', ()=> applyOverlay(item));
    div.addEventListener('keydown', e=> { if(e.key==='Enter') applyOverlay(item); });
    thumbsEl.appendChild(div);
  });
  thumbCount.textContent = `Showing ${combined.length} items (${currentGender})`;
}

/* -------------------------
  Apply overlay selection to canvas
  ------------------------- */
function applyOverlay(item){
  selectedItem = item;
  overlayState = { scale:1, rotate:0, yOffset:0, opacity:1 };
  scaleSlider.value = overlayState.scale;
  rotateSlider.value = overlayState.rotate;
  voffsetSlider.value = overlayState.yOffset;
  opacitySlider.value = overlayState.opacity;
  drawOverlay();
}

/* -------------------------
  Canvas drawing overlay + responsive sizing
  ------------------------- */
function ensureCanvasSize(){
  const rect = document.getElementById('videoPanel').getBoundingClientRect();
  overlayCanvas.width = Math.max(1, Math.floor(rect.width));
  overlayCanvas.height = Math.max(1, Math.floor(rect.height));
  overlayCanvas.style.width = rect.width+'px';
  overlayCanvas.style.height = rect.height+'px';
}
function drawOverlay(){
  ensureCanvasSize();
  overlayCtx.clearRect(0,0,overlayCanvas.width,overlayCanvas.height);
  if(!selectedItem) return;
  const img = new Image();
  img.onload = ()=>{
    const cw = overlayCanvas.width, ch = overlayCanvas.height;
    const cx = (overlayPos.xPercent/100)*cw;
    const cy = (overlayPos.yPercent/100)*ch + Number(overlayState.yOffset||0);
    const baseScale = (cw/1100);
    const drawW = img.width * overlayState.scale * baseScale;
    const drawH = img.height * overlayState.scale * baseScale;
    overlayCtx.save();
    overlayCtx.translate(cx, cy);
    overlayCtx.rotate((overlayState.rotate||0)*Math.PI/180);
    overlayCtx.globalAlpha = overlayState.opacity || 1;
    overlayCtx.drawImage(img, -drawW/2, -drawH/2, drawW, drawH);
    overlayCtx.restore();
  };
  img.src = selectedItem.url;
}

/* -------------------------
  Camera & MediaPipe FaceMesh integration
  ------------------------- */
async function startCameraAndFaceMesh(){
  try{
    stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:'user',width:{ideal:1280},height:{ideal:720}}, audio:false});
    cam.srcObject = stream;
    statusEl.textContent = 'Camera: on';
    startBtn.textContent = 'Turn Off Camera';

    faceMesh = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
    faceMesh.setOptions({ maxNumFaces:1, refineLandmarks:true, minDetectionConfidence:0.6, minTrackingConfidence:0.5});
    faceMesh.onResults(onFaceMeshResults);

    cameraFeed = new Camera(cam, {
      onFrame: async () => { await faceMesh.send({image: cam}); },
      width: 1280, height: 720
    });
    cameraFeed.start();
    attachResizeObserver();
  } catch(err) {
    console.error(err);
    alert('Camera access failed — check permissions and HTTPS.');
  }
}
function stopCamera(){
  if(cameraFeed && cameraFeed.stop) cameraFeed.stop();
  if(stream){ stream.getTracks().forEach(t=>t.stop()); stream=null; cam.srcObject=null; }
  statusEl.textContent = 'Camera: off';
  startBtn.textContent = 'Turn On Camera';
  faceMesh = null;
}
startBtn.addEventListener('click', ()=> { if(stream) stopCamera(); else startCameraAndFaceMesh(); });

function onFaceMeshResults(results){
  drawOverlay();
  if(!results.multiFaceLandmarks || results.multiFaceLandmarks.length===0) return;
  const lm = results.multiFaceLandmarks[0];
  let minX=1,minY=1,maxX=0,maxY=0;
  for(const p of lm){ if(p.x<minX) minX=p.x; if(p.y<minY) minY=p.y; if(p.x>maxX) maxX=p.x; if(p.y>maxY) maxY=p.y; }
  const cx = (minX+maxX)/2, cy=(minY+maxY)/2;
  const wNorm = maxX - minX;
  overlayPos.xPercent = (1-cx)*100;
  overlayPos.yPercent = clamp(cy*100 - 6, 12, 86);
  const scaleFactor = (wNorm / 0.30) * 1.12;
  overlayState.scale = clamp(scaleFactor, 0.28, 4.0);
  scaleSlider.value = overlayState.scale;
  const leftEye = lm[263] || lm[33], rightEye = lm[33] || lm[263];
  if(leftEye && rightEye){
    const dx = (leftEye.x - rightEye.x), dy = (leftEye.y - rightEye.y);
    const rollDeg = Math.atan2(dy, dx) * 180 / Math.PI;
    overlayState.rotate = rollDeg;
    rotateSlider.value = overlayState.rotate;
  }
  drawOverlay();
}

/* -------------------------
  Drag to position overlay
  ------------------------- */
document.getElementById('videoPanel').addEventListener('pointerdown', (ev)=>{
  if(!selectedItem) return;
  isDragging = true;
  updatePositionFromEvent(ev);
});
window.addEventListener('pointermove', (ev)=>{
  if(!isDragging || !selectedItem) return;
  updatePositionFromEvent(ev);
});
window.addEventListener('pointerup', ()=> isDragging=false);
function updatePositionFromEvent(ev){
  const rect = document.getElementById('videoPanel').getBoundingClientRect();
  const x = ev.clientX - rect.left, y = ev.clientY - rect.top;
  overlayPos.xPercent = (x / rect.width) * 100;
  overlayPos.yPercent = (y / rect.height) * 100;
  drawOverlay();
}

/* -------------------------
  Snapshot (video + overlay composite)
  ------------------------- */
function takeSnapshot(){
  if(!stream){ alert('Turn on the camera first.'); return; }
  ensureCanvasSize();
  const w = overlayCanvas.width, h = overlayCanvas.height;
  const tmp = document.createElement('canvas'); tmp.width=w; tmp.height=h;
  const ctx = tmp.getContext('2d');
  ctx.save(); ctx.scale(-1,1); ctx.drawImage(cam, -w, 0, w, h); ctx.restore();
  ctx.drawImage(overlayCanvas, 0, 0);
  tmp.toBlob(blob=>{
    const a = document.createElement('a'); a.href = URL.createObjectURL(blob); a.download = `hair-tryon-${Date.now()}.png`; document.body.appendChild(a); a.click(); a.remove();
  }, 'image/png');
}
snapBtn.addEventListener('click', takeSnapshot);

/* -------------------------
  Controls: sliders & buttons
  ------------------------- */
scaleSlider.addEventListener('input', e=> { overlayState.scale = parseFloat(e.target.value); drawOverlay(); });
rotateSlider.addEventListener('input', e=> { overlayState.rotate = parseFloat(e.target.value); drawOverlay(); });
voffsetSlider.addEventListener('input', e=> { overlayState.yOffset = parseFloat(e.target.value); drawOverlay(); });
opacitySlider.addEventListener('input', e=> { overlayState.opacity = parseFloat(e.target.value); drawOverlay(); });

fitBtn.addEventListener('click', ()=> { if(!stream || !faceMesh) alert('Turn on camera to auto-fit.'); else alert('Auto-fit enabled — move your head naturally for best result.'); });
resetBtn.addEventListener('click', ()=> { overlayState = {scale:1,rotate:0,yOffset:0,opacity:1}; overlayPos={xPercent:50,yPercent:32}; selectedItem=null; overlayCtx.clearRect(0,0,overlayCanvas.width,overlayCanvas.height); scaleSlider.value=1; rotateSlider.value=0; voffsetSlider.value=0; opacitySlider.value=1; });

randomBtn.addEventListener('click', ()=> { displayList = shuffle(displayList); renderThumbnails(); });
orderReset.addEventListener('click', ()=> { displayList = (currentGender==='boys') ? boysList.slice() : girlsList.slice(); renderThumbnails(); });

stylePreset.addEventListener('change', applyFilters);
quickSearch.addEventListener('input', applyFilters);
clearSearch.addEventListener('click', ()=> { quickSearch.value=''; applyFilters(); });

function applyFilters(){
  const preset = stylePreset.value;
  const q = quickSearch.value.trim().toLowerCase();
  const baseList = (currentGender==='boys') ? boysList.slice() : girlsList.slice();
  displayList = baseList.filter(item=>{
    if(preset!=='all' && !(item.tags && item.tags.includes(preset))) return false;
    if(q){
      if(q.startsWith('#')) { const num = parseInt(q.slice(1)); if(!isNaN(num)) return item.idx===num; }
      if(!( (item.tags && item.tags.join(' ').includes(q)) || item.id.toLowerCase().includes(q) || String(item.idx).includes(q) )) return false;
    }
    return true;
  });
  // append generated and uploads for the same gender
  const gens = generatedOverlays.filter(g=>g.gender===currentGender || true);
  displayList = displayList.concat(gens).concat(uploadedOverlays);
  renderThumbnails();
}

/* -------------------------
  Upload handling
  ------------------------- */
fileUpload.addEventListener('change', async (ev)=> {
  const files = Array.from(ev.target.files || []);
  for(const f of files){
    if(!f.type.startsWith('image/')) continue;
    const dataUrl = await readFileAsDataURL(f);
    uploadedOverlays.push({ id: uid('upload'), url: dataUrl, tags:['upload','png'], type:'png', idx: uploadedOverlays.length+1, gender: currentGender });
  }
  renderThumbnails();
  fileUpload.value = '';
});
clearUploads.addEventListener('click', ()=> { uploadedOverlays=[]; renderThumbnails(); });
function readFileAsDataURL(file){ return new Promise((res,rej)=>{ const r=new FileReader(); r.onload=()=>res(r.result); r.onerror=rej; r.readAsDataURL(file); }); }

/* -------------------------
  Helpers
  ------------------------- */
function shuffle(arr){ for(let i=arr.length-1;i>0;i--){ const j=Math.floor(Math.random()*(i+1)); [arr[i],arr[j]]=[arr[j],arr[i]] } return arr; }

/* Resize observer & draw loop */
function attachResizeObserver(){ const ro = new ResizeObserver(()=>{ ensureCanvasSize(); drawOverlay(); }); ro.observe(document.getElementById('videoPanel')); }
function loop(){ drawOverlay(); requestAnimationFrame(loop); }
loop();

/* -------------------------
  Initial generation & render pipeline
  ------------------------- */
async function startSequence(){
  thumbCount.textContent = 'Generating 200 ultra-realistic overlays — please wait...';
  // generate 200 overlays (100 boys then 100 girls)
  await generateAllOverlays(200);
  // build simple SVG-based libraries (100 each) for variety
  buildLibraries();
  // after building, set current display to boys
  currentGender='boys';
  displayList = boysList.concat(generatedOverlays).concat(uploadedOverlays);
  renderThumbnails();
}

// start generating immediately (user asked to do everything)
startSequence();

/* Set gender switches */
boysBtn.addEventListener('click', ()=>{ currentGender='boys'; boysBtn.classList.remove('ghost'); girlsBtn.classList.add('ghost'); applyFilters(); });
girlsBtn.addEventListener('click', ()=>{ currentGender='girls'; girlsBtn.classList.remove('ghost'); boysBtn.classList.add('ghost'); applyFilters(); });

/* Ensure canvas sized on load */
window.addEventListener('load', ()=> ensureCanvasSize());
</script>
</body>
</html>
